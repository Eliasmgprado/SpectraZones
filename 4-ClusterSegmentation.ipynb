{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "output_data_path = 'output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df_chem = pd.read_pickle('data/prominetHill_spec_chem_final_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(output_data_path, \"prominentHill_all_spectra_cr_cu_idxs.pkl\"), \"rb\"\n",
    ") as handle:\n",
    "    all_idxs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(output_data_path, \"prominentHill_all_spectra_cr_cu.pkl\"), \"rb\"\n",
    ") as f:\n",
    "    trainig_data, trainig_data_cu = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(\n",
    "        output_data_path, \"promintHill_all_spectra_cr_encoded_mdvpt_clusters.pkl\"\n",
    "    ),\n",
    "    \"rb\",\n",
    ") as handle:\n",
    "\n",
    "    all_spectra_cr_clusters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wvl_arr.pkl', 'rb') as f:\n",
    "    base_wvl_arr = pickle.load(f)\n",
    "swir_wvl_base = base_wvl_arr[0].astype(str).values\n",
    "tir_wvl_base = base_wvl_arr[1].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wvl_base = list(swir_wvl_base) + list([float(w) for w in tir_wvl_base])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the spectra for the selected indexes\n",
    "all_df = spec_df_chem.loc[all_idxs, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Depth (m)</th>\n",
       "      <th>Min1 uTSAS</th>\n",
       "      <th>Wt1 uTSAS</th>\n",
       "      <th>Min2 uTSAS</th>\n",
       "      <th>Wt2 uTSAS</th>\n",
       "      <th>Min3 uTSAS</th>\n",
       "      <th>Wt3 uTSAS</th>\n",
       "      <th>Error uTSAS</th>\n",
       "      <th>Min1 ujCLST</th>\n",
       "      <th>...</th>\n",
       "      <th>14300.0</th>\n",
       "      <th>14325.0</th>\n",
       "      <th>14350.0</th>\n",
       "      <th>14375.0</th>\n",
       "      <th>14400.0</th>\n",
       "      <th>14425.0</th>\n",
       "      <th>14450.0</th>\n",
       "      <th>14475.0</th>\n",
       "      <th>14500.0</th>\n",
       "      <th>Depth_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241877_0001_1</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123612</td>\n",
       "      <td>0.129789</td>\n",
       "      <td>0.135583</td>\n",
       "      <td>0.139656</td>\n",
       "      <td>0.141847</td>\n",
       "      <td>0.142505</td>\n",
       "      <td>0.142782</td>\n",
       "      <td>0.143598</td>\n",
       "      <td>0.145446</td>\n",
       "      <td>62.903017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241877_0001_2</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085993</td>\n",
       "      <td>0.089868</td>\n",
       "      <td>0.097571</td>\n",
       "      <td>0.108306</td>\n",
       "      <td>0.120761</td>\n",
       "      <td>0.132940</td>\n",
       "      <td>0.143911</td>\n",
       "      <td>0.152296</td>\n",
       "      <td>0.156787</td>\n",
       "      <td>62.903019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241877_0001_3</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103591</td>\n",
       "      <td>0.106344</td>\n",
       "      <td>0.113392</td>\n",
       "      <td>0.123753</td>\n",
       "      <td>0.135379</td>\n",
       "      <td>0.145596</td>\n",
       "      <td>0.153365</td>\n",
       "      <td>0.158294</td>\n",
       "      <td>0.160469</td>\n",
       "      <td>62.903011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241877_0001_4</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089949</td>\n",
       "      <td>0.090597</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>0.101330</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>0.124039</td>\n",
       "      <td>0.137684</td>\n",
       "      <td>0.150909</td>\n",
       "      <td>0.161748</td>\n",
       "      <td>62.903013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>241877_0001_5</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>0.087487</td>\n",
       "      <td>0.090884</td>\n",
       "      <td>0.098510</td>\n",
       "      <td>0.108330</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.124278</td>\n",
       "      <td>0.129234</td>\n",
       "      <td>0.132313</td>\n",
       "      <td>62.903014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sample  Depth (m) Min1 uTSAS  Wt1 uTSAS Min2 uTSAS  Wt2 uTSAS  \\\n",
       "0  241877_0001_1     62.903        NaN        NaN        NaN        NaN   \n",
       "1  241877_0001_2     62.903        NaN        NaN        NaN        NaN   \n",
       "2  241877_0001_3     62.903        NaN        NaN        NaN        NaN   \n",
       "3  241877_0001_4     62.903        NaN        NaN        NaN        NaN   \n",
       "4  241877_0001_5     62.903        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Min3 uTSAS  Wt3 uTSAS  Error uTSAS Min1 ujCLST  ...   14300.0   14325.0  \\\n",
       "0        NaN        NaN          NaN         NaN  ...  0.123612  0.129789   \n",
       "1        NaN        NaN          NaN         NaN  ...  0.085993  0.089868   \n",
       "2        NaN        NaN          NaN         NaN  ...  0.103591  0.106344   \n",
       "3        NaN        NaN          NaN         NaN  ...  0.089949  0.090597   \n",
       "4        NaN        NaN          NaN         NaN  ...  0.088858  0.087487   \n",
       "\n",
       "    14350.0   14375.0   14400.0   14425.0   14450.0   14475.0   14500.0  \\\n",
       "0  0.135583  0.139656  0.141847  0.142505  0.142782  0.143598  0.145446   \n",
       "1  0.097571  0.108306  0.120761  0.132940  0.143911  0.152296  0.156787   \n",
       "2  0.113392  0.123753  0.135379  0.145596  0.153365  0.158294  0.160469   \n",
       "3  0.094342  0.101330  0.111611  0.124039  0.137684  0.150909  0.161748   \n",
       "4  0.090884  0.098510  0.108330  0.117291  0.124278  0.129234  0.132313   \n",
       "\n",
       "   Depth_idx  \n",
       "0  62.903017  \n",
       "1  62.903019  \n",
       "2  62.903011  \n",
       "3  62.903013  \n",
       "4  62.903014  \n",
       "\n",
       "[5 rows x 900 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create From and To columns (for ploting points as intervals)\n",
    "def fromToCols(df, depth_col=\"Depth (m)\"):\n",
    "    print(df[\"DH_NAME\"].unique())\n",
    "    sorted_df = df.sort_values(by=depth_col)\n",
    "    depth_vals = sorted_df[depth_col].values\n",
    "    from_ = []\n",
    "    to_ = []\n",
    "    for i in range(len(depth_vals)):\n",
    "        if i == 0:\n",
    "            from_.append(depth_vals[i])\n",
    "            to_.append((depth_vals[i] + depth_vals[i+1])/2)\n",
    "        elif i == len(depth_vals)-1:\n",
    "            from_.append((depth_vals[i-1] + depth_vals[i])/2)\n",
    "            to_.append(depth_vals[i])\n",
    "        else:\n",
    "            from_.append((depth_vals[i-1] + depth_vals[i])/2)\n",
    "            to_.append((depth_vals[i] + depth_vals[i+1])/2)\n",
    "    \n",
    "    df[\"FROM_comp\"] = from_\n",
    "    df[\"TO_comp\"] = to_\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSG Columns grouped by DH_NAME and sorted by Depth\n",
    "tsg_cols_DH_g = all_df.iloc[:,:25].sort_values(by=\"Depth (m)\").groupby(\"DH_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['141786']\n",
      "['241877']\n",
      "['241878']\n",
      "['269223']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elias\\AppData\\Local\\Temp\\ipykernel_597928\\3564765794.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dh_results_df = tsg_cols_DH_g.apply(fromToCols)\n"
     ]
    }
   ],
   "source": [
    "dh_results_df = tsg_cols_DH_g.apply(fromToCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DH group idx\n",
    "dh_results_df = dh_results_df.reset_index(level=0, drop=True)\n",
    "# Reset order of samples\n",
    "dh_results_df = dh_results_df.loc[all_idxs, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Depth (m)</th>\n",
       "      <th>Min1 uTSAS</th>\n",
       "      <th>Wt1 uTSAS</th>\n",
       "      <th>Min2 uTSAS</th>\n",
       "      <th>Wt2 uTSAS</th>\n",
       "      <th>Min3 uTSAS</th>\n",
       "      <th>Wt3 uTSAS</th>\n",
       "      <th>Error uTSAS</th>\n",
       "      <th>Min1 ujCLST</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1 uTSAT</th>\n",
       "      <th>Wt1 uTSAT</th>\n",
       "      <th>Min2 uTSAT</th>\n",
       "      <th>Wt2 uTSAT</th>\n",
       "      <th>Min3 uTSAT</th>\n",
       "      <th>Wt3 uTSAT</th>\n",
       "      <th>Error uTSAT</th>\n",
       "      <th>DH_NAME</th>\n",
       "      <th>FROM_comp</th>\n",
       "      <th>TO_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241877_0001_1</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241877</td>\n",
       "      <td>62.903</td>\n",
       "      <td>62.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241877_0001_2</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241877</td>\n",
       "      <td>62.903</td>\n",
       "      <td>62.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241877_0001_3</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241877</td>\n",
       "      <td>62.903</td>\n",
       "      <td>62.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241877_0001_4</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241877</td>\n",
       "      <td>62.903</td>\n",
       "      <td>62.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>241877_0001_5</td>\n",
       "      <td>62.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241877</td>\n",
       "      <td>62.903</td>\n",
       "      <td>62.903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sample  Depth (m) Min1 uTSAS  Wt1 uTSAS Min2 uTSAS  Wt2 uTSAS  \\\n",
       "0  241877_0001_1     62.903        NaN        NaN        NaN        NaN   \n",
       "1  241877_0001_2     62.903        NaN        NaN        NaN        NaN   \n",
       "2  241877_0001_3     62.903        NaN        NaN        NaN        NaN   \n",
       "3  241877_0001_4     62.903        NaN        NaN        NaN        NaN   \n",
       "4  241877_0001_5     62.903        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Min3 uTSAS  Wt3 uTSAS  Error uTSAS Min1 ujCLST  ...  Min1 uTSAT Wt1 uTSAT  \\\n",
       "0        NaN        NaN          NaN         NaN  ...         NaN       NaN   \n",
       "1        NaN        NaN          NaN         NaN  ...         NaN       NaN   \n",
       "2        NaN        NaN          NaN         NaN  ...         NaN       NaN   \n",
       "3        NaN        NaN          NaN         NaN  ...         NaN       NaN   \n",
       "4        NaN        NaN          NaN         NaN  ...         NaN       NaN   \n",
       "\n",
       "   Min2 uTSAT Wt2 uTSAT  Min3 uTSAT  Wt3 uTSAT Error uTSAT DH_NAME  FROM_comp  \\\n",
       "0         NaN       NaN         NaN        NaN         NaN  241877     62.903   \n",
       "1         NaN       NaN         NaN        NaN         NaN  241877     62.903   \n",
       "2         NaN       NaN         NaN        NaN         NaN  241877     62.903   \n",
       "3         NaN       NaN         NaN        NaN         NaN  241877     62.903   \n",
       "4         NaN       NaN         NaN        NaN         NaN  241877     62.903   \n",
       "\n",
       "  TO_comp  \n",
       "0  62.903  \n",
       "1  62.903  \n",
       "2  62.903  \n",
       "3  62.903  \n",
       "4  62.903  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_results_df[\"clusters_dae_som\"]  = all_spectra_cr_clusters.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectraZones.tools.cluster_segmentation import ClusterSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSegmentation(\n",
    "    df,\n",
    "    depth_col=\"Depth (m)\",\n",
    "    cluster_col=\"clusters_dae_som\",\n",
    "    output_col=\"clusters_segmented\",\n",
    "):\n",
    "    print(\"Drill Hole: \", df[\"DH_NAME\"].unique())\n",
    "    cluster_segmentation = ClusterSegmentation(\n",
    "        df[depth_col].values,\n",
    "        df[cluster_col].values,\n",
    "        grid_spacing=2,\n",
    "    )\n",
    "    new_clusters = cluster_segmentation.compute_new_clusters()\n",
    "\n",
    "    df[output_col] = new_clusters.astype(int).astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drill Hole:  ['141786']\n",
      "Drill Hole:  ['241877']\n",
      "Drill Hole:  ['241878']\n",
      "Drill Hole:  ['269223']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elias\\AppData\\Local\\Temp\\ipykernel_597928\\3598262385.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dh_results_df_segmented = g.apply(\n"
     ]
    }
   ],
   "source": [
    "# Segment the clusters in each drill hole\n",
    "g = dh_results_df.groupby(\"DH_NAME\")\n",
    "dh_results_df_segmented = g.apply(\n",
    "    computeSegmentation, \"Depth (m)\", \"clusters_dae_som\", \"clusters_segmented\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DH group idx\n",
    "dh_results_df_segmented = dh_results_df_segmented.reset_index(level=0, drop=True)\n",
    "# Reset order of samples\n",
    "dh_results_df_segmented = dh_results_df_segmented.loc[all_idxs, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Cu values to the segmented clusters\n",
    "dh_results_df_segmented[\"Cu\"] = trainig_data_cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add logged lithology to result DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\DOUTORADO\\DL_Hyper_Borehole_Chem\\jupyter\\Clustering\\envs_\\Lib\\pickle.py:1718: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
      "  setstate(state)\n"
     ]
    }
   ],
   "source": [
    "# Load metadata df\n",
    "meta_df_arr = pd.read_pickle(\"data/prominentHill_meta_.pkl\")\n",
    "litho_meta_df = meta_df_arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata df indef for each sample\n",
    "# using the DH_NAME and Depth From/To\n",
    "\n",
    "# Create array to map the metadata index to the segmented clusters\n",
    "meta_idx_map = np.full(dh_results_df_segmented.shape[0], -1.)\n",
    "# Get the DH number and FROM/TO from each sample\n",
    "lito_samples = litho_meta_df[['DRILLHOLE_NO','DEPTH_FROM_M','DEPTH_TO_M']]\n",
    "# Iterate over the segmented clusters                          \n",
    "for j, i in enumerate(dh_results_df_segmented.index):\n",
    "    # Get the DH number and Depth for the current sample\n",
    "    dh_name, dep = dh_results_df_segmented.loc[i,['DH_NAME','Depth (m)']]\n",
    "    # Get the index of the metadata df for the current sample\n",
    "    # comparing sample DH and depth to the metadata from/to interval\n",
    "    lito_sample = lito_samples[(lito_samples['DRILLHOLE_NO'] == int(dh_name)) & \\\n",
    "                 (dep >= lito_samples['DEPTH_FROM_M']) & \\\n",
    "                 (dep < lito_samples['DEPTH_TO_M'])].index.values\n",
    "    \n",
    "    # If the sample is found, assign the index to the map\n",
    "    if lito_sample.shape[0] > 0:\n",
    "        meta_idx_map[j] = lito_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to extract from the metadata df\n",
    "meta_cols_to_extract = [\n",
    "    \"MAJOR_LITHOLOGY_CODE\",\n",
    "    \"MAJOR_LITHOLOGY_CONF\",\n",
    "    \"MAJOR_LITHOLOGY\",\n",
    "    \"MINOR_LITHOLOGY_CODE\",\n",
    "    \"MINOR_LITHOLOGY_CONF\",\n",
    "    \"MINOR_LITHOLOGY\",\n",
    "    \"DESCRIPTION\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the metadata for each sample\n",
    "dh_results_df_segmented[meta_cols_to_extract] = [\n",
    "    litho_meta_df.loc[x, meta_cols_to_extract] if x > -1 else np.nan\n",
    "    for x in meta_idx_map\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Cluster Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(output_data_path, \"prominentHill_swir_tir_cluster_results.pkl\"),\n",
    "    \"wb\",\n",
    ") as f:\n",
    "\n",
    "    pickle.dump(dh_results_df_segmented, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
